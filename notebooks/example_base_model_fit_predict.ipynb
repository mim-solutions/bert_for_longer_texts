{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b684d1c-49d8-4a89-80ee-8f54c4f6fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mbrzozowski/projects/media_monitoring/roberta_for_longer_texts\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ..\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f020349-c880-426d-a878-3089c79c9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config import VISIBLE_GPUS\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= VISIBLE_GPUS\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.main import BERTClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77184f93-d4e0-449f-8a5e-c9b1103d077c",
   "metadata": {},
   "source": [
    "## Load data - sample of IMDB reviews in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bddeba-98da-4eeb-b214-16318539a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA_PATH = 'test/sample_data/sample_data_eng.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84ad322-1484-4cd8-bf44-9bd7dcdb7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data for tests\n",
    "df = pd.read_csv(SAMPLE_DATA_PATH)\n",
    "\n",
    "texts = df['sentence'].tolist() # list of texts\n",
    "labels = df['target'].tolist() # list of 0/1 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1961058-55b7-456d-af4c-964c07b6cbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie not knowing anything about it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, don't let my summary fool you. This movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This should be re-titled \"The Curious Case Of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Those 2 points are dedicated the reasonable pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Following the success of the (awful) Gilligan'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>What if Marylin Monroe, Albert Einstein, Joe D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Such a film of beauty that it's hard to descri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>I saw this movie with my friend and we couldnt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>This is the best piece of film ever created It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>First of all, don't go into Revolver expecting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  target\n",
       "0     I saw this movie not knowing anything about it...       0\n",
       "1     OK, don't let my summary fool you. This movie ...       0\n",
       "2     This should be re-titled \"The Curious Case Of ...       0\n",
       "3     Those 2 points are dedicated the reasonable pe...       0\n",
       "4     Following the success of the (awful) Gilligan'...       0\n",
       "...                                                 ...     ...\n",
       "1995  What if Marylin Monroe, Albert Einstein, Joe D...       1\n",
       "1996  Such a film of beauty that it's hard to descri...       1\n",
       "1997  I saw this movie with my friend and we couldnt...       1\n",
       "1998  This is the best piece of film ever created It...       1\n",
       "1999  First of all, don't go into Revolver expecting...       1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5dcfa-bf7f-4202-a6b6-5ed256fbfd4d",
   "metadata": {},
   "source": [
    "## Divide to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1505f595-5990-4b90-8e75-eed4e4c4e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a129d-c4d1-465f-ae0f-8fd80318f45e",
   "metadata": {},
   "source": [
    "# Fit and predict methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d07f5-dad0-4612-9cf0-793716e79197",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39fde966-d26c-40e6-9c17-a1a108f7b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train accuracy: 0.765625, Train loss: 0.48031782753765584\n",
      "Epoch: 1, Train accuracy: 0.913125, Train loss: 0.21374331419356168\n",
      "Epoch: 2, Train accuracy: 0.970625, Train loss: 0.0887803716014605\n",
      "Epoch: 3, Train accuracy: 0.99125, Train loss: 0.038090710830874744\n",
      "Epoch: 4, Train accuracy: 0.991875, Train loss: 0.022266166053013875\n"
     ]
    }
   ],
   "source": [
    "# Loading model\n",
    "model = BERTClassificationModel()\n",
    "# Fitting a model to training data for 5 epochs\n",
    "model.fit(X_train,y_train,epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d1e36-a3e5-4e81-885d-48b91a6148e6",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b707a272-422d-4c7d-b5d0-fefcaec5b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probability for test set\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0904b3-7574-4861-bddf-a1dd4eee485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9990160465240479,\n",
       " 0.0017409994034096599,\n",
       " 0.9961218237876892,\n",
       " 0.0012668496929109097,\n",
       " 0.9986934065818787,\n",
       " 0.9990658164024353,\n",
       " 0.13043369352817535,\n",
       " 0.9990065693855286,\n",
       " 0.003581118769943714,\n",
       " 0.02430475503206253,\n",
       " 0.001389815704897046,\n",
       " 0.999092698097229,\n",
       " 0.9988080263137817,\n",
       " 0.006380797829478979,\n",
       " 0.0029083939734846354,\n",
       " 0.0015309338923543692,\n",
       " 0.001970528857782483,\n",
       " 0.0027299528010189533,\n",
       " 0.9984750151634216,\n",
       " 0.18142493069171906,\n",
       " 0.0015611917478963733,\n",
       " 0.998988926410675,\n",
       " 0.9891312122344971,\n",
       " 0.9402116537094116,\n",
       " 0.99897301197052,\n",
       " 0.003055406268686056,\n",
       " 0.9952387809753418,\n",
       " 0.001839455682784319,\n",
       " 0.0019281472777947783,\n",
       " 0.002766823396086693,\n",
       " 0.0018383283168077469,\n",
       " 0.008376440033316612,\n",
       " 0.0013053157599642873,\n",
       " 0.004930502735078335,\n",
       " 0.9989734888076782,\n",
       " 0.0017147460021078587,\n",
       " 0.9989871382713318,\n",
       " 0.9989839196205139,\n",
       " 0.9981731176376343,\n",
       " 0.006210676860064268,\n",
       " 0.0036184536293148994,\n",
       " 0.9991233944892883,\n",
       " 0.00770837627351284,\n",
       " 0.0027479210402816534,\n",
       " 0.9373252391815186,\n",
       " 0.0020939011592417955,\n",
       " 0.0018920665606856346,\n",
       " 0.0033587212674319744,\n",
       " 0.001865872647613287,\n",
       " 0.999160885810852,\n",
       " 0.9986289739608765,\n",
       " 0.00363258202560246,\n",
       " 0.9991856217384338,\n",
       " 0.0023813648149371147,\n",
       " 0.0017997227841988206,\n",
       " 0.16181638836860657,\n",
       " 0.9222389459609985,\n",
       " 0.4670691192150116,\n",
       " 0.999110758304596,\n",
       " 0.0030717095360159874,\n",
       " 0.9989720582962036,\n",
       " 0.0025853354018181562,\n",
       " 0.9989750385284424,\n",
       " 0.9979866743087769,\n",
       " 0.9989497065544128,\n",
       " 0.9990541338920593,\n",
       " 0.007483629509806633,\n",
       " 0.9365601539611816,\n",
       " 0.0014899607049301267,\n",
       " 0.9982536435127258,\n",
       " 0.0017985787708312273,\n",
       " 0.0030999118462204933,\n",
       " 0.9982714653015137,\n",
       " 0.9984819293022156,\n",
       " 0.0023002163507044315,\n",
       " 0.0028772945515811443,\n",
       " 0.9990266561508179,\n",
       " 0.0020345004741102457,\n",
       " 0.003993975464254618,\n",
       " 0.992508590221405,\n",
       " 0.0028454032726585865,\n",
       " 0.6605824828147888,\n",
       " 0.9976580142974854,\n",
       " 0.9989936947822571,\n",
       " 0.9979897737503052,\n",
       " 0.005624907091259956,\n",
       " 0.9984620809555054,\n",
       " 0.002009372226893902,\n",
       " 0.0023353048600256443,\n",
       " 0.0020058832596987486,\n",
       " 0.9987068176269531,\n",
       " 0.5986326336860657,\n",
       " 0.005482861306518316,\n",
       " 0.0038801280315965414,\n",
       " 0.9988470077514648,\n",
       " 0.999099612236023,\n",
       " 0.0023609811905771494,\n",
       " 0.992389976978302,\n",
       " 0.9991716146469116,\n",
       " 0.993769109249115,\n",
       " 0.976033091545105,\n",
       " 0.0016761538572609425,\n",
       " 0.014783677645027637,\n",
       " 0.9942289590835571,\n",
       " 0.8930078148841858,\n",
       " 0.005727152805775404,\n",
       " 0.0019243393326178193,\n",
       " 0.0024729922879487276,\n",
       " 0.0024379510432481766,\n",
       " 0.001743796980008483,\n",
       " 0.0018773127812892199,\n",
       " 0.9990721940994263,\n",
       " 0.9957758784294128,\n",
       " 0.9991455078125,\n",
       " 0.0018229704583063722,\n",
       " 0.0034925632644444704,\n",
       " 0.9991963505744934,\n",
       " 0.006748523563146591,\n",
       " 0.004982650745660067,\n",
       " 0.9985164999961853,\n",
       " 0.999000608921051,\n",
       " 0.9986417889595032,\n",
       " 0.9991368651390076,\n",
       " 0.0017374419840052724,\n",
       " 0.0027529606595635414,\n",
       " 0.9870878458023071,\n",
       " 0.0019097687909379601,\n",
       " 0.0026238481514155865,\n",
       " 0.9957776069641113,\n",
       " 0.0020157392136752605,\n",
       " 0.9923015832901001,\n",
       " 0.9983256459236145,\n",
       " 0.0034552928991615772,\n",
       " 0.030265899375081062,\n",
       " 0.21288545429706573,\n",
       " 0.9947295784950256,\n",
       " 0.9987095594406128,\n",
       " 0.999066174030304,\n",
       " 0.9989368319511414,\n",
       " 0.9980224370956421,\n",
       " 0.01150897890329361,\n",
       " 0.00230162194930017,\n",
       " 0.969286322593689,\n",
       " 0.0022991385776549578,\n",
       " 0.9990672469139099,\n",
       " 0.0026152273640036583,\n",
       " 0.0020358464680612087,\n",
       " 0.998445451259613,\n",
       " 0.9935746788978577,\n",
       " 0.010156029835343361,\n",
       " 0.9878822565078735,\n",
       " 0.00652830395847559,\n",
       " 0.004108477383852005,\n",
       " 0.9988598823547363,\n",
       " 0.9774655103683472,\n",
       " 0.0016324043972417712,\n",
       " 0.0977843850851059,\n",
       " 0.9991143345832825,\n",
       " 0.001550575252622366,\n",
       " 0.9991436004638672,\n",
       " 0.001732850563712418,\n",
       " 0.001909909537062049,\n",
       " 0.0066978768445551395,\n",
       " 0.9951735138893127,\n",
       " 0.9990593791007996,\n",
       " 0.9986792206764221,\n",
       " 0.9991521835327148,\n",
       " 0.9988616704940796,\n",
       " 0.005286060273647308,\n",
       " 0.3580414056777954,\n",
       " 0.9988325238227844,\n",
       " 0.683032214641571,\n",
       " 0.001644075382500887,\n",
       " 0.20008796453475952,\n",
       " 0.0029611317440867424,\n",
       " 0.9989498257637024,\n",
       " 0.0018635658780112863,\n",
       " 0.9990353584289551,\n",
       " 0.012107809074223042,\n",
       " 0.9897497296333313,\n",
       " 0.9921729564666748,\n",
       " 0.7452569603919983,\n",
       " 0.9986652135848999,\n",
       " 0.9977194666862488,\n",
       " 0.30865222215652466,\n",
       " 0.054150402545928955,\n",
       " 0.9988827109336853,\n",
       " 0.9991533756256104,\n",
       " 0.9980286955833435,\n",
       " 0.9962635636329651,\n",
       " 0.0020350348204374313,\n",
       " 0.001840270939283073,\n",
       " 0.0027502886950969696,\n",
       " 0.002196963643655181,\n",
       " 0.005128195974975824,\n",
       " 0.5770310163497925,\n",
       " 0.9974766373634338,\n",
       " 0.0022120156791061163,\n",
       " 0.0045140525326132774,\n",
       " 0.8629410862922668,\n",
       " 0.9988368153572083,\n",
       " 0.0014413964236155152,\n",
       " 0.0020476514473557472,\n",
       " 0.003955845255404711,\n",
       " 0.002618533791974187,\n",
       " 0.0036824101116508245,\n",
       " 0.999121367931366,\n",
       " 0.9991463422775269,\n",
       " 0.9985339641571045,\n",
       " 0.002339382190257311,\n",
       " 0.8689008951187134,\n",
       " 0.007297673728317022,\n",
       " 0.0018607511883601546,\n",
       " 0.002674760762602091,\n",
       " 0.14761821925640106,\n",
       " 0.9280352592468262,\n",
       " 0.9969891905784607,\n",
       " 0.9802554845809937,\n",
       " 0.0030879094265401363,\n",
       " 0.002673777751624584,\n",
       " 0.0012320593232288957,\n",
       " 0.002094860887154937,\n",
       " 0.45744848251342773,\n",
       " 0.9991401433944702,\n",
       " 0.9991777539253235,\n",
       " 0.9989449381828308,\n",
       " 0.9973579049110413,\n",
       " 0.002011803677305579,\n",
       " 0.9979470372200012,\n",
       " 0.001712308032438159,\n",
       " 0.9991422891616821,\n",
       " 0.0028607542626559734,\n",
       " 0.9991018772125244,\n",
       " 0.9960893392562866,\n",
       " 0.9940496683120728,\n",
       " 0.9613324403762817,\n",
       " 0.9990978240966797,\n",
       " 0.0017865500412881374,\n",
       " 0.9777063727378845,\n",
       " 0.0035942362155765295,\n",
       " 0.5470247864723206,\n",
       " 0.9990033507347107,\n",
       " 0.002303448971360922,\n",
       " 0.9654261469841003,\n",
       " 0.9988923668861389,\n",
       " 0.015399900265038013,\n",
       " 0.9953706860542297,\n",
       " 0.9524729251861572,\n",
       " 0.0025149588473141193,\n",
       " 0.9987574815750122,\n",
       " 0.6485299468040466,\n",
       " 0.1868334412574768,\n",
       " 0.9987071752548218,\n",
       " 0.004290651995688677,\n",
       " 0.06477541476488113,\n",
       " 0.9991852641105652,\n",
       " 0.0015136481961235404,\n",
       " 0.0019071500282734632,\n",
       " 0.9990563988685608,\n",
       " 0.8121764063835144,\n",
       " 0.45332828164100647,\n",
       " 0.9988241791725159,\n",
       " 0.004322074819356203,\n",
       " 0.998977541923523,\n",
       " 0.9983075857162476,\n",
       " 0.1805284023284912,\n",
       " 0.002695696661248803,\n",
       " 0.002423327649012208,\n",
       " 0.006775896996259689,\n",
       " 0.9235268831253052,\n",
       " 0.981639564037323,\n",
       " 0.9988505840301514,\n",
       " 0.0014951648190617561,\n",
       " 0.9991576671600342,\n",
       " 0.0027071572840213776,\n",
       " 0.9989573955535889,\n",
       " 0.0013625535648316145,\n",
       " 0.6694334745407104,\n",
       " 0.9977278113365173,\n",
       " 0.004544454626739025,\n",
       " 0.9974083304405212,\n",
       " 0.9990181922912598,\n",
       " 0.0023385221138596535,\n",
       " 0.9985223412513733,\n",
       " 0.9984017014503479,\n",
       " 0.0016136488411575556,\n",
       " 0.0027870715130120516,\n",
       " 0.9989288449287415,\n",
       " 0.001844142097979784,\n",
       " 0.0024005735758692026,\n",
       " 0.9990928173065186,\n",
       " 0.9990027546882629,\n",
       " 0.008762224577367306,\n",
       " 0.9986708164215088,\n",
       " 0.0026629052590578794,\n",
       " 0.00111881154589355,\n",
       " 0.002336651785299182,\n",
       " 0.9990586638450623,\n",
       " 0.9990214109420776,\n",
       " 0.001756967161782086,\n",
       " 0.005315585061907768,\n",
       " 0.003905084216967225,\n",
       " 0.9938517808914185,\n",
       " 0.9986805319786072,\n",
       " 0.0018049851059913635,\n",
       " 0.003221280639991164,\n",
       " 0.20357809960842133,\n",
       " 0.04494624584913254,\n",
       " 0.3155709207057953,\n",
       " 0.0035051668528467417,\n",
       " 0.41850048303604126,\n",
       " 0.8800468444824219,\n",
       " 0.999092698097229,\n",
       " 0.003206400666385889,\n",
       " 0.9986883997917175,\n",
       " 0.4085317850112915,\n",
       " 0.002000888343900442,\n",
       " 0.9990466237068176,\n",
       " 0.9990246295928955,\n",
       " 0.9988707900047302,\n",
       " 0.0033507116604596376,\n",
       " 0.9966835379600525,\n",
       " 0.3375118672847748,\n",
       " 0.0017500353278592229,\n",
       " 0.00371539662592113,\n",
       " 0.001645706477575004,\n",
       " 0.9989480376243591,\n",
       " 0.002880450803786516,\n",
       " 0.9608173370361328,\n",
       " 0.002405520062893629,\n",
       " 0.0030454089865088463,\n",
       " 0.0028425229247659445,\n",
       " 0.03884430229663849,\n",
       " 0.07291875779628754,\n",
       " 0.001266904640942812,\n",
       " 0.9991976618766785,\n",
       " 0.0015659603523090482,\n",
       " 0.0022646128199994564,\n",
       " 0.9987653493881226,\n",
       " 0.9988827109336853,\n",
       " 0.9964078068733215,\n",
       " 0.4084126651287079,\n",
       " 0.9439408779144287,\n",
       " 0.0048292153514921665,\n",
       " 0.45604047179222107,\n",
       " 0.0784260705113411,\n",
       " 0.0019021880580112338,\n",
       " 0.02464042231440544,\n",
       " 0.9967999458312988,\n",
       " 0.0021266229450702667,\n",
       " 0.9971848130226135,\n",
       " 0.0024332439061254263,\n",
       " 0.9991053938865662,\n",
       " 0.9900614023208618,\n",
       " 0.0027447976171970367,\n",
       " 0.9971966743469238,\n",
       " 0.9991747736930847,\n",
       " 0.9989765882492065,\n",
       " 0.9309227466583252,\n",
       " 0.9988287091255188,\n",
       " 0.0020935845095664263,\n",
       " 0.08898484706878662,\n",
       " 0.6376855373382568,\n",
       " 0.013476856984198093,\n",
       " 0.002546882489696145,\n",
       " 0.010639503598213196,\n",
       " 0.9973606467247009,\n",
       " 0.0023490507155656815,\n",
       " 0.9983099699020386,\n",
       " 0.0026130788028240204,\n",
       " 0.10206255316734314,\n",
       " 0.9631977677345276,\n",
       " 0.007907872088253498,\n",
       " 0.999160647392273,\n",
       " 0.9965606331825256,\n",
       " 0.9954820871353149,\n",
       " 0.0017534289509057999,\n",
       " 0.9225420951843262,\n",
       " 0.9990440011024475,\n",
       " 0.9991549253463745,\n",
       " 0.9991621971130371,\n",
       " 0.20034337043762207,\n",
       " 0.0016308164922520518,\n",
       " 0.9988040924072266,\n",
       " 0.993930459022522,\n",
       " 0.03114667534828186,\n",
       " 0.002227947348728776,\n",
       " 0.007151434198021889,\n",
       " 0.003250101115554571,\n",
       " 0.9988073110580444,\n",
       " 0.9988806843757629,\n",
       " 0.9982680082321167,\n",
       " 0.001991208177059889,\n",
       " 0.6784844398498535,\n",
       " 0.00441485783085227,\n",
       " 0.0020484330598264933,\n",
       " 0.9978474378585815,\n",
       " 0.0614105686545372,\n",
       " 0.0032525653950870037,\n",
       " 0.0022963564842939377]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b381253-e76d-4764-ad3f-caccc67e4610",
   "metadata": {},
   "source": [
    "## Calculate model accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9767e0-39e9-4581-b462-24a0f0f536eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = (np.array(preds) >= 0.5)\n",
    "accurate = sum(predicted_classes == np.array(y_test).astype(bool))\n",
    "accuracy = accurate/len(y_test)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bert_long]",
   "language": "python",
   "name": "conda-env-.conda-bert_long-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
