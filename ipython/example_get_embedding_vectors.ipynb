{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a7a120-277c-4614-a161-7e7cf06469fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mbrzozowski/projects/media_monitoring/roberta_for_longer_texts\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ..\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204dccca-bb43-4e1c-a5ad-f853b0ce4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config import VISIBLE_GPUS\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= VISIBLE_GPUS\n",
    "import torch\n",
    "\n",
    "from lib.main import BERTClassificationModelWithPooling, load_pretrained_model\n",
    "from lib.text_preprocessors import BERTTokenizerPooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61056050-cede-4579-9134-d93a51b2ffc9",
   "metadata": {},
   "source": [
    "# Get embedding vectors for longer sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb478c29-e631-4121-975d-8e5cff16263f",
   "metadata": {},
   "source": [
    "## Load example text longer than 512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bec30e-c113-4b3b-95e0-dc48b0f3a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA_PATH = 'test/sample_data/sample_data_eng.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4def68bd-3d13-4c03-968b-405aac3bbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(SAMPLE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1f2db0-6454-4a32-8f57-82d2f443b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_words'] = df['sentence'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b0d501-3aa1-4281-86b5-39d293c471de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Okay, so I'm not a big video game buff, but wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Jim Carrey is back to much the same role that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>THE SHOP AROUND THE CORNER is one of the sweet...</td>\n",
       "      <td>1</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>I won't try to speculate as to what Brando was...</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Pier Paolo Pasolini, or Pee-pee-pee as I prefe...</td>\n",
       "      <td>0</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>Predictable plot. Simple dialogue. Shockingly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>This unpretentious Horror film is probably des...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>THis movie shows us once again, how genius the...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>The only thing serious about this movie is the...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>It is an almost ideal romantic anime! MUST SEE...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  target  \\\n",
       "961   Okay, so I'm not a big video game buff, but wa...       0   \n",
       "1054  Jim Carrey is back to much the same role that ...       1   \n",
       "1456  THE SHOP AROUND THE CORNER is one of the sweet...       1   \n",
       "1711  I won't try to speculate as to what Brando was...       1   \n",
       "68    Pier Paolo Pasolini, or Pee-pee-pee as I prefe...       0   \n",
       "...                                                 ...     ...   \n",
       "859   Predictable plot. Simple dialogue. Shockingly ...       0   \n",
       "1151  This unpretentious Horror film is probably des...       1   \n",
       "1374  THis movie shows us once again, how genius the...       1   \n",
       "1655  The only thing serious about this movie is the...       1   \n",
       "1743  It is an almost ideal romantic anime! MUST SEE...       1   \n",
       "\n",
       "      number_of_words  \n",
       "961              1316  \n",
       "1054             1277  \n",
       "1456             1148  \n",
       "1711             1000  \n",
       "68                997  \n",
       "...               ...  \n",
       "859                33  \n",
       "1151               32  \n",
       "1374               30  \n",
       "1655               28  \n",
       "1743               28  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='number_of_words', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6135d4-9be0-4e13-af55-afc3c706a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = df.loc[961,'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47885958-f439-4dc5-8ef0-c75555b6db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I'm not a big video game buff, but was the game House of the Dead really famous enough to make a movie from? Sure, they went as far as to actually put in quick video game clips throughout the movie, as though justifying any particular scene of violence, but there are dozens and dozens of games that look exactly the same, with the hand in the bottom on the screen, supposedly your own, holding whatever weapon and goo-ing all kinds of aliens or walking dead or snipers or whatever the case may be.<br /><br />It's an interesting premise in House of the Dead, with a lot of college kids (LOADED college kids, as it were, kids who are able to pay some fisherman something like $1,500 just for a ride after they miss their boat) trying to get out to this island for what is supposed to be the rave of the year. The first thing that comes to mind about House of the Dead after watching it is that it has become increasingly clear that modern horror movies have become nothing more than an exercise in coming up with creative ways to get a lot of scantily clad teenagers into exactly the same situations. At least in this case, the fact that they were on their way to a rave excuses the way the girls are dressed. They look badly out of place running around the woods in cute little halter-tops, but at least they THOUGHT they were dressed for the occasion.<br /><br />Clint Howard, tellingly the most interesting character in the film by far, delivers an absolutely awful performance, the greatness of which overshadows every other actor in the movie. I can't stand it when well-known actors change their accents in movies, it is so rarely effective, and Howard here shows that it is equally flat to have an well-known actor pretend that he's this hardened fisherman with a raspy voice from years of breathing salty air. He didn't even rasp well. It sounded like he was eating a cinnamon roll before shooting and accidentally inhaled some powdered sugar or something. Real tough there, Clint! I expected more from him, but then again, he did agree to a part in this mess.<br /><br />Once we get to the island, the movie temporarily turns into any one of the Friday the 13th movies that took place at Camp Crystal Lake. Lots of teenagers played by actors who were way too old for their parts getting naked and then killed. The nudity was impressive, I guess, but let's consider something for a minute. These kids pay almost two grand to get out to this island to go to the Rave Of The Year, find NO ONE, and say, well, who wants a beer! Even the guy who pulled that stack of hundreds out of his wallet to get them all over there didn't think anything of it that they found a full bar and not a single solitary person in sight. Here you have the input from director Uwe Boll - There's alcohol! They won't notice that the party they came for consists of no one but themselves!<br /><br />So not only do they start drinking, not minding the fact that the whole party seems to have vacated the island, but when one of the girls goes off into the dark woods to find out where everyone is (dragging one other girl and one of the guys reluctantly along), the guy and the girl who stay behind to get smashed decide that it would be a great idea to strip down for a quickie now that they're alone. It's like they expected to find the island empty, and now that they rest of the people that they came over with were gone for a little while, they would have some privacy since there's no one else around. Brilliant!<br /><br />Now for the things that everyone hated, judging by the reviews that I've read about the movie. Yes, intersplicing shots from the video game into the movie, mostly in order to show that, yes, the movie was being faithful to/directly copying the video game. Sure, it was a stupid idea. I can't imagine who thought up that little nugget, but worse than that is the Matrix-style bullet time scenes that were thrown in over and over and over and over. After the first time (at which point I found it pretentious and cheesy for a movie like this to have a shot like that as though it was something original) it is noticeable more for the technique of the shot itself rather than any dramatic meaning or creation of any kind of tension for the film.<br /><br />One of the things that makes a zombie film scary and gets you on the edge of your seat is to have them slowly but relentlessly coming after the living humans, who are much faster but getting tired, running out of places to run, and with a terrifying shortage of things with which to fight the zombies off with. The first two are done right in the movie, the kids are terrified and don't have a lot of places to run since they're on an island, but since they caught a ride over with a smuggler, they find themselves heavily armed. And I mean that very strongly. I mean, these people have everything from machine guns to hand grenades, which removes most of the tension of the impending walking dead.<br /><br />Then you have what I call the techno-slasher scene. Since the rave never happened, and I guess since Uwe Boll thought people were going to be disappointed at not hearing any techno music in the movie, there's one scene right in the middle where all the humans are fighting off the living dead, and amazingly enough it turns into something of a music video. There's techno music blasting as the shots are edited together faster and faster until it's nothing but a blur of gory shot, mostly only about 5 frames long (which is about 1/6 of a second) flashing across the screen in time with the speed techno music. Clever, I guess, but it has no place in a horror movie because it completely removes any sense of scariness or tension of even the gross-out effect because you can't see any one thing for long enough to react to it. You're just watching these shots fly across the screen and wondering what the hell the director was thinking when he decided that it would be a good idea to put something like this in the movie.<br /><br />I've seen a lot of people compare this movie to Resident Evil, mostly claiming that it copies the premise of it, and they're exactly right. I appreciate that at least here, as was not the case in Resident Evil, it wasn't some man-made virus that turned people into walking dead that were able to infect other people, changing them the way vampires turn others into vampires. 28 Days Later was also clearly an inspiration for this movie, it's just too bad that House of the Dead didn't do a single original thing, except for the somewhat moronic idea of putting in quick shots of the video game on which it is based, just in case you forget. I really think that this should have been a much better movie. While obviously I can't say that I know much about the game it's based on, just the title and the movie poster deserve a much better movie, but unfortunately I think that's more often the case than not with horror movies. It's really kind of sad when a movie comes out that is so obviously advertised as a no-holds-barred horror film, and the scariest thing in the entire movie is the closing shot, which suggests the possibility of a sequel.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8aaf2-56d2-4a64-af90-af0792c8fd9d",
   "metadata": {},
   "source": [
    "## Load BERT tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00aac3b3-f9d8-4779-a53c-efbfb735bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer, bert = load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a084f2-9894-4bd8-ab07-4ba8c8d84cbd",
   "metadata": {},
   "source": [
    "## Split longer texts into chunks and tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adc47f-53b2-472b-9d96-d8bcd1195445",
   "metadata": {},
   "source": [
    "### Set splitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1b9272-7550-4d73-a389-dc226933432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 510\n",
    "step = 256\n",
    "minimal_length = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3f86b-4400-4be9-bbbf-7d5e129bebeb",
   "metadata": {},
   "source": [
    "### Split and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a01c9fbe-5f4e-4e3a-9410-b4f2690fe6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = BERTTokenizerPooled(tokenizer,size,step,minimal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7472f3da-d0ab-410c-9768-ba2193c3218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "model_inputs = preprocessor.preprocess([example_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a71aed-d2a2-496a-8b3d-511b79c462ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [tensor([[  101,  3100,  1010,  ...,  2893,  6248,   102],\n",
       "          [  101,  2037,  2126,  ...,  2058,  2007,   102],\n",
       "          [  101,  2730,  1012,  ...,  1998,  2007,   102],\n",
       "          ...,\n",
       "          [  101, 15843,  1997,  ...,  2074,  1996,   102],\n",
       "          [  101,  3168,  1997,  ...,     0,     0,     0],\n",
       "          [  101,  1996,  3185,  ...,     0,     0,     0]])],\n",
       " 'attention_mask': [tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d59634-6551-406b-b6b3-de50f1a1d112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75263aa4-12f9-4e01-9314-de9d41516959",
   "metadata": {},
   "source": [
    "Hence the text was divided into 7 chunks. Each consists of 512 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6263b-7ef4-4b5c-8979-f6839d415b10",
   "metadata": {},
   "source": [
    "### Get tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5cb345a-26ce-4993-8b12-b315e7ea7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = model_inputs['input_ids'][0]\n",
    "attention_masks = model_inputs['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ded07-4f4e-4a67-abf8-85df76f1f3c2",
   "metadata": {},
   "source": [
    "### Put them on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb7d59d6-7fdf-4ade-8033-8e84220838cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.to('cuda',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feb430f5-6b4a-4b0b-9438-0944d1f8dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = attention_masks.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc8432-9add-4539-abec-a3004d830e1a",
   "metadata": {},
   "source": [
    "### Check that all tensors and model are on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67226230-b5fc-4857-b92a-8abcc2207fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0753a319-99cd-4baf-98a9-f776e6445e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f098b051-01cb-42e1-98d5-c443e87dc5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab78144-aedc-4fbc-8e26-1eebb04c31f8",
   "metadata": {},
   "source": [
    "## Get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32b81474-9c51-48c2-97f9-ab99076d40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert(input_ids,attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86b46d22-c3ae-4c37-b568-c9e1a91e62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "067c19a1-5dbe-4b6b-97ce-625a624612ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e18a5-9867-455a-9f4b-4bd252cbf01d",
   "metadata": {},
   "source": [
    "Obtained embedding is a tensor of the size:\n",
    "- 7 (number of text chunks) times\n",
    "- 512 (number of tokens per text chunk) times\n",
    "- 768 (embedding space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67b405fb-2df9-44be-939c-0b0cf967cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1334, -0.1360,  0.0732,  ...,  0.1593,  0.7489,  0.0912],\n",
       "         [ 0.6643,  0.3044,  0.2671,  ...,  0.6427,  1.4492,  0.5313],\n",
       "         [-0.3382,  0.2624,  0.5635,  ..., -0.0744,  0.6455,  0.9595],\n",
       "         ...,\n",
       "         [ 0.2310,  0.5090,  0.0892,  ...,  0.1037,  0.0765, -0.2995],\n",
       "         [ 0.9082,  0.1428, -0.1060,  ..., -0.3137,  0.3477, -1.2582],\n",
       "         [ 0.5154,  0.3602,  0.1636,  ...,  0.5111,  0.3805, -0.1014]],\n",
       "\n",
       "        [[ 0.0297, -0.0376,  0.2539,  ..., -0.1259,  0.7356,  0.1644],\n",
       "         [-0.3283, -0.0473, -0.3935,  ...,  0.2280,  1.2034,  0.4672],\n",
       "         [-0.2061, -0.4288,  0.2502,  ...,  0.0781,  0.2309,  0.4196],\n",
       "         ...,\n",
       "         [ 0.8271, -0.8116, -0.3419,  ...,  0.9582,  0.1719, -0.1047],\n",
       "         [-0.1106, -0.0820, -0.6049,  ...,  0.3202,  0.4953, -0.3978],\n",
       "         [ 0.2317,  0.5210,  0.3277,  ...,  0.6629,  0.2948, -0.2424]],\n",
       "\n",
       "        [[ 0.1567, -0.1907,  0.3564,  ...,  0.0833,  0.4848,  0.2843],\n",
       "         [ 1.1954,  0.3024,  0.9446,  ...,  0.0882,  0.7422,  0.0325],\n",
       "         [-0.8346, -0.3901,  0.3148,  ...,  0.4805,  0.9593, -0.4966],\n",
       "         ...,\n",
       "         [-0.5219,  0.3236, -0.1667,  ..., -0.2202,  0.6941,  0.1185],\n",
       "         [-0.5833,  0.5325,  0.2625,  ...,  0.0712,  0.5977, -0.5449],\n",
       "         [ 0.6165,  0.3795,  0.5488,  ...,  0.5624,  0.4126, -0.1926]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2680, -0.3931,  0.2302,  ...,  0.1447,  0.8079,  0.2935],\n",
       "         [-0.0364,  0.2946,  0.1124,  ...,  0.1687,  0.6349,  0.1993],\n",
       "         [-0.1121,  0.4516, -0.1183,  ..., -0.0199, -0.2004,  0.3615],\n",
       "         ...,\n",
       "         [-0.4075, -0.4365, -0.1270,  ...,  1.2071,  0.7641,  0.9629],\n",
       "         [-0.5720, -1.0628, -0.3882,  ...,  0.4872,  0.8303, -0.5085],\n",
       "         [ 0.4964,  0.0407,  0.1252,  ...,  0.5979,  0.4534, -0.2051]],\n",
       "\n",
       "        [[ 0.3774, -0.3187, -0.0925,  ...,  0.2237,  0.8803,  0.5854],\n",
       "         [-0.4358,  0.4075, -0.1162,  ..., -0.3599,  0.8208,  0.7769],\n",
       "         [-0.5835, -0.0322,  0.0876,  ..., -0.6396,  0.0531,  0.3435],\n",
       "         ...,\n",
       "         [ 0.0302,  0.1388,  0.0322,  ...,  0.0443,  0.0639,  0.1837],\n",
       "         [-0.1126, -0.5747,  0.3499,  ...,  0.3815,  0.2970, -0.0652],\n",
       "         [ 0.0514, -0.2805,  0.4825,  ...,  0.1544,  0.1550, -0.1464]],\n",
       "\n",
       "        [[ 0.4398, -0.0639, -0.2800,  ...,  0.1364,  0.6999,  0.5852],\n",
       "         [ 0.2781,  0.0822, -0.1979,  ...,  0.0719,  1.0609, -0.3698],\n",
       "         [ 0.9049, -0.4381,  0.3115,  ...,  0.2214,  0.5591, -0.0162],\n",
       "         ...,\n",
       "         [-0.8168, -0.2243,  0.5329,  ...,  0.2179, -0.3991, -0.4202],\n",
       "         [-0.1703, -0.3271,  0.3188,  ...,  0.0539,  0.1395, -0.2561],\n",
       "         [ 0.3356, -0.2880,  0.3687,  ...,  0.0785,  0.2469, -0.4300]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2b220-6f6e-4c02-a047-a3a3c6f049fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-roberta_for_longer_texts]",
   "language": "python",
   "name": "conda-env-.conda-roberta_for_longer_texts-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
